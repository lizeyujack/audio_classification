{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5b7f02433d4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0msave_mfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJSON_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_segments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-5b7f02433d4d>\u001b[0m in \u001b[0;36msave_mfcc\u001b[1;34m(dataset_path, json_path, num_mfcc, n_fft, hop_length, num_segments)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         \"mfcc\": []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#     }\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.json\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "DATASET_PATH = \"de\"\n",
    "JSON_PATH = \"data.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 1 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
    "\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param json_path (str): Path to json file used to save MFCCs\n",
    "        :param num_mfcc (int): Number of coefficients to extract\n",
    "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
    "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
    "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "# dictionary to store mapping, labels, and MFCCs\n",
    "#     data = {\n",
    "#         \"mapping\": [],\n",
    "#         \"labels\": [],\n",
    "#         \"mfcc\": []\n",
    "#     }\n",
    "    with open(\"data.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            # process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "                # load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    # extract mfcc\n",
    "                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)#修改 i+(n-2)\n",
    "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "                            # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: C0001\n",
      "de\\C0001\\IC0001W0001.wav, segment:1\n",
      "de\\C0001\\IC0001W0001.wav, segment:2\n",
      "de\\C0001\\IC0001W0001.wav, segment:3\n",
      "de\\C0001\\IC0001W0001.wav, segment:4\n",
      "de\\C0001\\IC0001W0001.wav, segment:5\n",
      "de\\C0001\\IC0001W0001.wav, segment:6\n",
      "de\\C0001\\IC0001W0001.wav, segment:7\n",
      "de\\C0001\\IC0001W0001.wav, segment:8\n",
      "de\\C0001\\IC0001W0001.wav, segment:9\n",
      "de\\C0001\\IC0001W0001.wav, segment:10\n",
      "de\\C0001\\IC0001W0002.wav, segment:1\n",
      "de\\C0001\\IC0001W0002.wav, segment:2\n",
      "de\\C0001\\IC0001W0002.wav, segment:3\n",
      "de\\C0001\\IC0001W0002.wav, segment:4\n",
      "de\\C0001\\IC0001W0002.wav, segment:5\n",
      "de\\C0001\\IC0001W0002.wav, segment:6\n",
      "de\\C0001\\IC0001W0002.wav, segment:7\n",
      "de\\C0001\\IC0001W0002.wav, segment:8\n",
      "de\\C0001\\IC0001W0002.wav, segment:9\n",
      "de\\C0001\\IC0001W0002.wav, segment:10\n",
      "de\\C0001\\IC0001W0003.wav, segment:1\n",
      "de\\C0001\\IC0001W0003.wav, segment:2\n",
      "de\\C0001\\IC0001W0003.wav, segment:3\n",
      "de\\C0001\\IC0001W0003.wav, segment:4\n",
      "de\\C0001\\IC0001W0003.wav, segment:5\n",
      "de\\C0001\\IC0001W0003.wav, segment:6\n",
      "de\\C0001\\IC0001W0003.wav, segment:7\n",
      "de\\C0001\\IC0001W0003.wav, segment:8\n",
      "de\\C0001\\IC0001W0003.wav, segment:9\n",
      "de\\C0001\\IC0001W0003.wav, segment:10\n",
      "de\\C0001\\IC0001W0004.wav, segment:1\n",
      "de\\C0001\\IC0001W0004.wav, segment:2\n",
      "de\\C0001\\IC0001W0004.wav, segment:3\n",
      "de\\C0001\\IC0001W0004.wav, segment:4\n",
      "de\\C0001\\IC0001W0004.wav, segment:5\n",
      "de\\C0001\\IC0001W0004.wav, segment:6\n",
      "de\\C0001\\IC0001W0004.wav, segment:7\n",
      "de\\C0001\\IC0001W0004.wav, segment:8\n",
      "de\\C0001\\IC0001W0004.wav, segment:9\n",
      "de\\C0001\\IC0001W0004.wav, segment:10\n",
      "de\\C0001\\IC0001W0005.wav, segment:1\n",
      "de\\C0001\\IC0001W0005.wav, segment:2\n",
      "de\\C0001\\IC0001W0005.wav, segment:3\n",
      "de\\C0001\\IC0001W0005.wav, segment:4\n",
      "de\\C0001\\IC0001W0005.wav, segment:5\n",
      "de\\C0001\\IC0001W0005.wav, segment:6\n",
      "de\\C0001\\IC0001W0005.wav, segment:7\n",
      "de\\C0001\\IC0001W0005.wav, segment:8\n",
      "de\\C0001\\IC0001W0005.wav, segment:9\n",
      "de\\C0001\\IC0001W0005.wav, segment:10\n",
      "\n",
      "Processing: C0002\n",
      "de\\C0002\\IC0002W0001.wav, segment:1\n",
      "de\\C0002\\IC0002W0001.wav, segment:2\n",
      "de\\C0002\\IC0002W0001.wav, segment:3\n",
      "de\\C0002\\IC0002W0001.wav, segment:4\n",
      "de\\C0002\\IC0002W0001.wav, segment:5\n",
      "de\\C0002\\IC0002W0001.wav, segment:6\n",
      "de\\C0002\\IC0002W0001.wav, segment:7\n",
      "de\\C0002\\IC0002W0001.wav, segment:8\n",
      "de\\C0002\\IC0002W0001.wav, segment:9\n",
      "de\\C0002\\IC0002W0001.wav, segment:10\n",
      "de\\C0002\\IC0002W0002.wav, segment:1\n",
      "de\\C0002\\IC0002W0002.wav, segment:2\n",
      "de\\C0002\\IC0002W0002.wav, segment:3\n",
      "de\\C0002\\IC0002W0002.wav, segment:4\n",
      "de\\C0002\\IC0002W0002.wav, segment:5\n",
      "de\\C0002\\IC0002W0002.wav, segment:6\n",
      "de\\C0002\\IC0002W0002.wav, segment:7\n",
      "de\\C0002\\IC0002W0002.wav, segment:8\n",
      "de\\C0002\\IC0002W0002.wav, segment:9\n",
      "de\\C0002\\IC0002W0002.wav, segment:10\n",
      "de\\C0002\\IC0002W0003.wav, segment:1\n",
      "de\\C0002\\IC0002W0003.wav, segment:2\n",
      "de\\C0002\\IC0002W0003.wav, segment:3\n",
      "de\\C0002\\IC0002W0003.wav, segment:4\n",
      "de\\C0002\\IC0002W0003.wav, segment:5\n",
      "de\\C0002\\IC0002W0003.wav, segment:6\n",
      "de\\C0002\\IC0002W0003.wav, segment:7\n",
      "de\\C0002\\IC0002W0003.wav, segment:8\n",
      "de\\C0002\\IC0002W0003.wav, segment:9\n",
      "de\\C0002\\IC0002W0003.wav, segment:10\n",
      "de\\C0002\\IC0002W0004.wav, segment:1\n",
      "de\\C0002\\IC0002W0004.wav, segment:2\n",
      "de\\C0002\\IC0002W0004.wav, segment:3\n",
      "de\\C0002\\IC0002W0004.wav, segment:4\n",
      "de\\C0002\\IC0002W0004.wav, segment:5\n",
      "de\\C0002\\IC0002W0004.wav, segment:6\n",
      "de\\C0002\\IC0002W0004.wav, segment:7\n",
      "de\\C0002\\IC0002W0004.wav, segment:8\n",
      "de\\C0002\\IC0002W0004.wav, segment:9\n",
      "de\\C0002\\IC0002W0004.wav, segment:10\n",
      "de\\C0002\\IC0002W0005.wav, segment:1\n",
      "de\\C0002\\IC0002W0005.wav, segment:2\n",
      "de\\C0002\\IC0002W0005.wav, segment:3\n",
      "de\\C0002\\IC0002W0005.wav, segment:4\n",
      "de\\C0002\\IC0002W0005.wav, segment:5\n",
      "de\\C0002\\IC0002W0005.wav, segment:6\n",
      "de\\C0002\\IC0002W0005.wav, segment:7\n",
      "de\\C0002\\IC0002W0005.wav, segment:8\n",
      "de\\C0002\\IC0002W0005.wav, segment:9\n",
      "de\\C0002\\IC0002W0005.wav, segment:10\n",
      "\n",
      "Processing: C9001\n",
      "de\\C9001\\IC0001W0006.wav, segment:1\n",
      "de\\C9001\\IC0001W0006.wav, segment:2\n",
      "de\\C9001\\IC0001W0006.wav, segment:3\n",
      "de\\C9001\\IC0001W0006.wav, segment:4\n",
      "de\\C9001\\IC0001W0006.wav, segment:5\n",
      "de\\C9001\\IC0001W0006.wav, segment:6\n",
      "de\\C9001\\IC0001W0006.wav, segment:7\n",
      "de\\C9001\\IC0001W0006.wav, segment:8\n",
      "de\\C9001\\IC0001W0006.wav, segment:9\n",
      "de\\C9001\\IC0001W0006.wav, segment:10\n",
      "de\\C9001\\IC0001W0007.wav, segment:1\n",
      "de\\C9001\\IC0001W0007.wav, segment:2\n",
      "de\\C9001\\IC0001W0007.wav, segment:3\n",
      "de\\C9001\\IC0001W0007.wav, segment:4\n",
      "de\\C9001\\IC0001W0007.wav, segment:5\n",
      "de\\C9001\\IC0001W0007.wav, segment:6\n",
      "de\\C9001\\IC0001W0007.wav, segment:7\n",
      "de\\C9001\\IC0001W0007.wav, segment:8\n",
      "de\\C9001\\IC0001W0007.wav, segment:9\n",
      "de\\C9001\\IC0001W0007.wav, segment:10\n",
      "de\\C9001\\IC0001W0008.wav, segment:1\n",
      "de\\C9001\\IC0001W0008.wav, segment:2\n",
      "de\\C9001\\IC0001W0008.wav, segment:3\n",
      "de\\C9001\\IC0001W0008.wav, segment:4\n",
      "de\\C9001\\IC0001W0008.wav, segment:5\n",
      "de\\C9001\\IC0001W0008.wav, segment:6\n",
      "de\\C9001\\IC0001W0008.wav, segment:7\n",
      "de\\C9001\\IC0001W0008.wav, segment:8\n",
      "de\\C9001\\IC0001W0008.wav, segment:9\n",
      "de\\C9001\\IC0001W0008.wav, segment:10\n",
      "de\\C9001\\IC0001W0009.wav, segment:1\n",
      "de\\C9001\\IC0001W0009.wav, segment:2\n",
      "de\\C9001\\IC0001W0009.wav, segment:3\n",
      "de\\C9001\\IC0001W0009.wav, segment:4\n",
      "de\\C9001\\IC0001W0009.wav, segment:5\n",
      "de\\C9001\\IC0001W0009.wav, segment:6\n",
      "de\\C9001\\IC0001W0009.wav, segment:7\n",
      "de\\C9001\\IC0001W0009.wav, segment:8\n",
      "de\\C9001\\IC0001W0009.wav, segment:9\n",
      "de\\C9001\\IC0001W0009.wav, segment:10\n",
      "de\\C9001\\IC0001W0010.wav, segment:1\n",
      "de\\C9001\\IC0001W0010.wav, segment:2\n",
      "de\\C9001\\IC0001W0010.wav, segment:3\n",
      "de\\C9001\\IC0001W0010.wav, segment:4\n",
      "de\\C9001\\IC0001W0010.wav, segment:5\n",
      "de\\C9001\\IC0001W0010.wav, segment:6\n",
      "de\\C9001\\IC0001W0010.wav, segment:7\n",
      "de\\C9001\\IC0001W0010.wav, segment:8\n",
      "de\\C9001\\IC0001W0010.wav, segment:9\n",
      "de\\C9001\\IC0001W0010.wav, segment:10\n",
      "\n",
      "Processing: C9002\n",
      "de\\C9002\\IC0002W0006.wav, segment:1\n",
      "de\\C9002\\IC0002W0006.wav, segment:2\n",
      "de\\C9002\\IC0002W0006.wav, segment:3\n",
      "de\\C9002\\IC0002W0006.wav, segment:4\n",
      "de\\C9002\\IC0002W0006.wav, segment:5\n",
      "de\\C9002\\IC0002W0006.wav, segment:6\n",
      "de\\C9002\\IC0002W0006.wav, segment:7\n",
      "de\\C9002\\IC0002W0006.wav, segment:8\n",
      "de\\C9002\\IC0002W0006.wav, segment:9\n",
      "de\\C9002\\IC0002W0006.wav, segment:10\n",
      "de\\C9002\\IC0002W0007.wav, segment:1\n",
      "de\\C9002\\IC0002W0007.wav, segment:2\n",
      "de\\C9002\\IC0002W0007.wav, segment:3\n",
      "de\\C9002\\IC0002W0007.wav, segment:4\n",
      "de\\C9002\\IC0002W0007.wav, segment:5\n",
      "de\\C9002\\IC0002W0007.wav, segment:6\n",
      "de\\C9002\\IC0002W0007.wav, segment:7\n",
      "de\\C9002\\IC0002W0007.wav, segment:8\n",
      "de\\C9002\\IC0002W0007.wav, segment:9\n",
      "de\\C9002\\IC0002W0007.wav, segment:10\n",
      "de\\C9002\\IC0002W0008.wav, segment:1\n",
      "de\\C9002\\IC0002W0008.wav, segment:2\n",
      "de\\C9002\\IC0002W0008.wav, segment:3\n",
      "de\\C9002\\IC0002W0008.wav, segment:4\n",
      "de\\C9002\\IC0002W0008.wav, segment:5\n",
      "de\\C9002\\IC0002W0008.wav, segment:6\n",
      "de\\C9002\\IC0002W0008.wav, segment:7\n",
      "de\\C9002\\IC0002W0008.wav, segment:8\n",
      "de\\C9002\\IC0002W0008.wav, segment:9\n",
      "de\\C9002\\IC0002W0008.wav, segment:10\n",
      "de\\C9002\\IC0002W0009.wav, segment:1\n",
      "de\\C9002\\IC0002W0009.wav, segment:2\n",
      "de\\C9002\\IC0002W0009.wav, segment:3\n",
      "de\\C9002\\IC0002W0009.wav, segment:4\n",
      "de\\C9002\\IC0002W0009.wav, segment:5\n",
      "de\\C9002\\IC0002W0009.wav, segment:6\n",
      "de\\C9002\\IC0002W0009.wav, segment:7\n",
      "de\\C9002\\IC0002W0009.wav, segment:8\n",
      "de\\C9002\\IC0002W0009.wav, segment:9\n",
      "de\\C9002\\IC0002W0009.wav, segment:10\n",
      "de\\C9002\\IC0002W0010.wav, segment:1\n",
      "de\\C9002\\IC0002W0010.wav, segment:2\n",
      "de\\C9002\\IC0002W0010.wav, segment:3\n",
      "de\\C9002\\IC0002W0010.wav, segment:4\n",
      "de\\C9002\\IC0002W0010.wav, segment:5\n",
      "de\\C9002\\IC0002W0010.wav, segment:6\n",
      "de\\C9002\\IC0002W0010.wav, segment:7\n",
      "de\\C9002\\IC0002W0010.wav, segment:8\n",
      "de\\C9002\\IC0002W0010.wav, segment:9\n",
      "de\\C9002\\IC0002W0010.wav, segment:10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "DATASET_PATH = \"de\"\n",
    "JSON_PATH = \"data.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 0.5 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, num_mfcc=10, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
    "\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param json_path (str): Path to json file used to save MFCCs\n",
    "        :param num_mfcc (int): Number of coefficients to extract\n",
    "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
    "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
    "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"\\\\\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            # process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "                # load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    # extract mfcc\n",
    "                    \n",
    "                    try:\n",
    "                        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                        mfcc = mfcc.T\n",
    "                    except:\n",
    "                        continue\n",
    "                    # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i+1-2)#i+(n-2)\n",
    "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# DATA_PATH = \"/content/drive/My Drive/南国训练集/test.json\"\n",
    "data_path = \"data.json\"\n",
    "\n",
    "with open(data_path, \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "X = np.array(data[\"mfcc\"])\n",
    "y = np.array(data[\"labels\"])\n",
    "    \n",
    "# create train, validation and test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
